# RAG PoC 시스템 디버깅 및 개선 기록

이 문서는 RAG PoC 시스템을 구축하고 안정화하는 과정에서 발생했던 주요 문제들과 그 해결 과정을 기록한 문서입니다.

## 1. 초기 문제: 답변 생성 실패 ("관련 문서를 찾을 수 없습니다")

### 1.1. 증상
- 모든 질문에 대해 "죄송합니다. 관련 문서를 찾을 수 없습니다." 라는 답변만 반환됨.

### 1.2. 원인 분석
- **1차 원인: 임시 데이터베이스 사용**: `chromadb.Client()`로 생성된 벡터 DB는 스크립트 종료 시 메모리에서 사라짐. `vector_db.py` 실행 후, `rag_poc.py`가 실행될 때는 비어있는 DB에 접근하게 되어 문서 검색에 실패함.
- **2차 원인: 잘못된 실행 위치**: `rag_poc.py`를 프로젝트 루트(`D:\workspace`)에서 실행하여, 스크립트가 데이터베이스 경로(`.\chroma_db`)를 `D:\workspace\chroma_db`로 인식함. 실제 데이터베이스는 `D:\workspace\rag_poc\chroma_db`에 있었으므로, 비어있는 새 DB를 생성하게 됨.

### 1.3. 해결 과정
- **1차 해결**: `chromadb.PersistentClient(path=".\chroma_db")`를 사용하도록 코드를 수정하여, 데이터베이스를 파일 형태로 영구 저장함.
- **2차 해결**: 스크립트 실행 전, `cd D:\workspace\rag_poc` 명령어를 통해 스크립트가 위치한 디렉터리로 이동하여, 올바른 상대 경로로 데이터베이스를 찾아가도록 프로세스를 변경함.

---

## 2. 중기 문제: 부정확한 문서 참조 및 답변 품질 저하

### 2.1. 증상
- "모의해킹" 관련 질문에 대해, 정답이 담긴 `모의해킹.txt`가 아닌 `시스템개요.txt` 등 엉뚱한 문서를 참고함.
- LLM이 생성한 답변이 의미 없는 URL 목록이거나, 프롬프트의 일부를 반복하는 등 품질이 매우 낮았음.

### 2.2. 원인 분석
- **1차 원인: 데이터베이스 오염**: `vector_db.py`를 반복 실행하는 과정에서 기존 데이터가 삭제되지 않고 계속 중복으로 쌓임. 이로 인해 검색 시 관련 없는 문서가 더 높은 유사도를 갖게 되어 검색 정확도가 저하됨.
- **2차 원인: LLM의 한계와 모호한 프롬프트**: `EleutherAI/polyglot-ko-1.3b` 모델이 `---`와 같은 구분자를 제대로 이해하지 못하고, 여러 문서를 한 번에 제공했을 때 핵심 정보를 파악하는 데 어려움을 겪음.

### 2.3. 해결 과정
- **1차 해결: DB 초기화 로직 추가**: `vector_db.py` 실행 시, 기존 컬렉션을 먼저 삭제(`delete_collection`)한 후 새로 생성하도록 코드를 수정하여 항상 최신 상태의 깨끗한 데이터베이스를 유지함.
- **2차 해결: 프롬프트 엔지니어링**: `### 질문 ###`, `### 답변 ###` 과 같은 명확한 마크다운 형식으로 프롬프트를 구조화하여 LLM이 각 섹션의 역할을 명확히 인지하도록 개선함.

---

## 3. 후기 문제: 답변 내용의 신뢰성 부족 (Hallucination)

### 3.1. 증상
- "모의해킹 조치완료일" 질문에 대해, 문서에 없는 "5월 30일"이라는 거짓 정보를 생성함.
- 질문의 의도와 상관없이, 참고 문서의 내용을 그대로 요약하거나 반복하는 경향을 보임.

### 3.2. 원인 분석
- **1차 원인: LLM의 높은 랜덤성**: `temperature` 기본값이 높아, 모델이 확률적으로 가장 높은 단어 대신 창의적이고 예측 불가능한 답변을 생성하려는 경향이 있었음.
- **2차 원인: 부적합한 모델**: `polyglot-ko-1.3b` 모델은 일반적인 언어 생성에는 강점이 있으나, 주어진 지시사항(Instruction)을 정확히 따르는 능력은 부족했음.
- **3차 원인: 데이터 품질**: "조치완료일: 20250801"과 같은 단순 나열식 데이터는 모델이 의미를 명확하게 파악하기 어려웠음.
- **4차 원인: 불필요한 정보(Noise)**: 관련성이 낮은 여러 문서를 한 번에 참고 자료로 제공하자, LLM이 핵심 정보에 집중하지 못하고 혼란을 겪음.

### 3.3. 해결 과정
- **1차 해결: 생성 옵션 제어**: `temperature=0.1`로 값을 낮춰 LLM의 랜덤성을 줄이고, `max_new_tokens=64`로 답변 길이를 제한하여 안정성을 높임.
- **2차 해결: 모델 교체**: 지시사항 수행 능력에 더 특화된 `beomi/KoAlpaca-Polyglot-5.8B` 모델로 교체하여 프롬프트 이해도를 높임.
- **3차 해결: 데이터 품질 개선**: `모의해킹.txt`의 내용을 "모의해킹 조치완료일은 2025년 8월 1일입니다." 와 같이 명확한 서술형 문장으로 수정하여 모델의 이해를 도움.
- **4차 해결: 정보 집중**: 검색 결과(`n_results`)를 1개로 다시 줄여, LLM이 가장 관련성 높은 핵심 문서에만 집중하도록 유도함.

## 최종 결론

초기 RAG 시스템은 다양한 원인으로 불안정하게 동작했으나, **데이터베이스 관리, 프롬프트 엔지니어링, LLM 모델 및 옵션 제어, 데이터 품질 개선** 등 체계적인 디버깅 과정을 통해 안정적이고 신뢰도 높은 PoC 시스템을 완성할 수 있었다.