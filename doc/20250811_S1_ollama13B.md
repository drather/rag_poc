# Ollama 13B 모델 적용 TODO LIST

## 1. Ollama 모델 준비
- [ ] Ollama CLI를 통해 원하는 13B 모델 (예: `koalpaca-13b` 또는 `eeve-korean-10.8b:latest`) pull

## 2. `rag_poc.py` 수정
- [ ] `langchain_community.llms.LlamaCpp` 대신 `langchain_community.llms.Ollama`를 사용하도록 코드 변경
- [ ] `llm = Ollama(model="koalpaca-13b")`와 같이 모델 로딩 부분 수정

## 3. RAG 파이프라인 테스트
- [ ] 수정된 `rag_poc.py`를 실행하여 Ollama와 연동이 잘 되는지 확인
- [ ] `WIN 193` 오류가 해결되고 RAG 파이프라인이 정상 작동하는지 검증

## 4. `requirements.txt` 업데이트 (필요시)
- [ ] `langchain-community` 또는 `ollama` 관련 라이브러리 추가/업데이트 확인